<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<title>reveal.js</title>

		<link rel="stylesheet" href="reveal.js/dist/reset.css">
		<link rel="stylesheet" href="reveal.js/dist/reveal.css">
		<link rel="stylesheet" href="custom-serif.css" id="theme">

		<!-- Theme used for syntax highlighted code -->
		<link rel="stylesheet" href="reveal.js/plugin/highlight/monokai.css" id="highlight-theme">
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section id="title">
                                    <h2>Métodos de subespacios de Krylov</h2>
                                    <h4>y sus aplicaciones a la Dinámica Browniana</h4>
                                    <h3>Edwin Armando Bedolla Montiel</h3>
                                    <h5>12 de febrero, 2021, Grupo de Materia Blanda.</h5>
                                </section>
				<section id="toc">
                                    <h3>Contenido</h3>
                                    <ol>
                                        <li>¿Qué son los métodos de subespacios de
                                            Krylov?</li>
                                        <li>Ejemplos: sistemas lineales y descomposición
                                            espectral.</li>
                                        <li>Interacciones hidrodinámicas en dinámica
                                            Browniana.</li>
                                    </ol>
                                </section>
                                <section>
                                    <h3>Definición</h3>
                                    Sea \( A \) una matriz invertible de \( n \times n \), y sea
                                    \( b \) un vector de dimensión \( n \), entonces, un
                                    subespacio de Krylov de orden \( r \) está definido
                                    como
                                    \[\begin{equation}
                                        \mathcal{K}_r(A, b) = \text{span} \{ b, Ab, A^2 b, A^3 b,
                                        \dots, A^{r-1} b\}
                                    \end{equation}
                                    \]
                                </section>
                                <section>
                                    <section>
                                        <h3>Aproximaciones</h3>
                                        Esto significa que podemos crear un subespacio
                                        lineal usando solamente \( A, \) y \( b. \)
                                    </section>
                                    <section>
                                        Para visualizar esto, podemos pensar en las series
                                        de Taylor
                                        \[
                                        f(x-a)=\sum_{n=0}^{\infty}\frac{f^{(n)}(a)}{n!}(x-a)^n
                                        \]
                                    </section>
                                    <section>
                                        Las series de Taylor nos dan una buena
                                        aproximación de la función \( f(x). \)
                                    </section>
                                    <section>
                                        \[ e^x = \sum_{n=0}^{\infty} \frac{x^n}{n!} \]
                                    </section>
                                    <section>
                                        \[ e^1 = \sum_{n=0}^{N=10}
                                        \frac{1^n}{n!}=2.718281801146385 \]
                                        \[ e = 2.718281828459045 \]
                                    </section>
                                    <section>
                                        De la misma forma, el subespacio de Krylov \(
                                        \mathcal{K}_r \) nos da
                                        una buena aproximación del producto \( Ab. \)
                                    </section>
                                </section>
                                <section>
                                    <section>
                                    ¿En qué tipo de <b>problemas</b> puedo aplicar estos métodos?
                                    </section>
                                    <section>
                                        <h3>Regresión lineal</h3>
                                        Se quiere resolver el problema 
                                        \[ \mathbf{y}=\mathbf{X \beta} + \mathbf{\epsilon} \]
                                        <aside class="notes">
                                            Epsilon es un "ruido blanco", o "ruido
                                            gaussiano". Es ruido en las mediciones.
                                        </aside>
                                    </section>
                                    <section>
                                        <img src="assets/regression.png">
                                    </section>
                                    <section>
                                        Si se reorganiza el problema a un <b>sistema
                                            lineal</b>
                                        \[ \mathbf{X^T y} = \mathbf{X^T X \beta} \]
                                        donde ahora se multiplica por la matriz
                                        transpuesta para que la matriz \( X^T X \) sea una
                                        matriz cuadrada<a href="#footnote-1">[1]</a>.
                                        <aside class="notes">
                                            Esta matriz se conoce como matriz normal o
                                            matriz de cofactores de beta
                                        </aside>
                                    </section>
                                    <section>
                                        Para problemas pequeños, la solución al problema
                                        es simple. Uno de lo más conocidos es mediante la
                                        descomposición \( LU \).
                                    </section>
                                    <section>
                                        Toda matriz cuadrada tiene descomposición
                                        \[ PA = LU \]
                                        donde \( P \) es una matriz de permutaciones entre
                                        las filas; \( L \) es una matriz triangular
                                        <em>inferior</em>; y \( U \) es una matriz tringular
                                        <em>superior</em>.
                                    </section>
                                    <section>
                                        La solución es, entonces
                                        \[ P \mathbf{y} = P \mathbf{X^T X \beta} = LU
                                        \beta \]
                                        Es decir, primero se resuelve el problema
                                        \[ Lz = P\mathbf{y} \]
                                        y luego
                                        \[ U \mathbf{\beta} = z \]
                                    </section>
                                    <section>
                                        Pero <b>¡ojo!</b>, nótese que la operación
                                        \[ \mathbf{X^T \beta} \]
                                        da como resultado a un vector, y aún más, ¡se
                                        parece a nuestra definición de \( \mathcal{K}_r
                                        \)!
                                    </section>
                                </section>
                                <section>
                                    <h3>Método del gradiente conjugado</h3>
                                    <section>
                                        Podemos entonces construir un subespacio de Krylov
                                        tal que 
                                        \[
                                        \mathcal{K}_r (A^T A, A^T b) \equiv \text{span} \{
                                        A^T b, (A^T A) A^T b, (A^T A)^2 A^T b, \\ (A^T A)^3 A^T b,
                                        \dots, (A^T A)^{r-1} A^T b \}
                                        \]
                                    </section>
                                    <section>
                                        Dado que es un <em>espacio lineal</em> nos
                                        preguntamos, entonces, ¿cuál es la
                                        <b>mejor</b> combinación lineal que resuelve el
                                        problema?
                                    </section>
                                </section>
			</div>
		</div>

		<script src="reveal.js/dist/reveal.js"></script>
		<script src="reveal.js/plugin/notes/notes.js"></script>
		<script src="reveal.js/plugin/markdown/markdown.js"></script>
		<script src="reveal.js/plugin/highlight/highlight.js"></script>
                <script src="reveal.js/plugin/math/math.js"></script>
		<script>
			// More info about initialization & config:
			// - https://revealjs.com/initialization/
			// - https://revealjs.com/config/
			Reveal.initialize({
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealMarkdown, RevealHighlight, RevealNotes,
                                                        RevealMath ]
			});
		</script>
	</body>
</html>
